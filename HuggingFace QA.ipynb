{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HuggingFace Transformers for QA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing dependences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m pip install --upgrade pip\n",
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers[tf-cpu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers[sentencepiece]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "import torch as pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = r\"\"\"\n",
    "    ðŸ¤— Transformers (formerly known as pytorch-transformers and pytorch-pretrained-bert) provides general-purpose\n",
    "    architectures (BERT, GPT-2, RoBERTa, XLM, DistilBert, XLNetâ€¦) for Natural Language Understanding (NLU) and Natural\n",
    "    Language Generation (NLG) with over 32+ pretrained models in 100+ languages and deep interoperability between\n",
    "    TensorFlow 2.0 and PyTorch.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"How many pretrained models are available in ðŸ¤— Transformers?\",\n",
    "    \"How many languages are available in ðŸ¤— Transformers?\",\n",
    "    \"What does ðŸ¤— Transformers provide?\",\n",
    "     \"ðŸ¤— Transformers provides interoperability between which frameworks?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44e2bec9128b449ea4607397ebae6cfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab8cc2da35ad46a6aed189b88774077c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d9d4ce1c1df4a8083e3b515f5edf145",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qanlp = pipeline('question-answering')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 'over 32+', score: 0.5266, start: 268, end: 276\n",
      "Answer: '100+', score: 0.5444, start: 298, end: 302\n",
      "Answer: 'general-purpose\n",
      "    architectures', score: 0.9541, start: 98, end: 131\n",
      "Answer: 'TensorFlow 2.0 and PyTorch', score: 0.8424, start: 351, end: 377\n"
     ]
    }
   ],
   "source": [
    "result = qanlp(question=questions, context=text)\n",
    "for res in result:\n",
    "    print(f\"Answer: '{res['answer']}', score: {round(res['score'], 4)}, start: {res['start']}, end: {res['end']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selected model (example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'csarron/bert-base-uncased-squad-v1'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many pretrained models are available in ðŸ¤— Transformers?\n",
      "Answer: 32 +\n",
      "Start Confidence: 0.6249579191207886\n",
      "End Confidence: 0.0002813107566908002\n",
      "Question: How many languages are available in ðŸ¤— Transformers?\n",
      "Answer: 100 +\n",
      "Start Confidence: 0.8915950059890747\n",
      "End Confidence: 0.17126747965812683\n",
      "Question: What does ðŸ¤— Transformers provide?\n",
      "Answer: general - purpose architectures\n",
      "Start Confidence: 0.9812468886375427\n",
      "End Confidence: 7.347790233325213e-05\n",
      "Question: ðŸ¤— Transformers provides interoperability between which frameworks?\n",
      "Answer: tensorflow 2. 0 and pytorch\n",
      "Start Confidence: 0.9922741055488586\n",
      "End Confidence: 0.09956756979227066\n"
     ]
    }
   ],
   "source": [
    "for question in questions:\n",
    "    inputs = tokenizer(question, text, add_special_tokens=True, return_tensors=\"pt\")\n",
    "    input_ids = inputs[\"input_ids\"].tolist()[0]\n",
    "\n",
    "    text_tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "    outputs = model(**inputs)\n",
    "    answer_start_scores = outputs.start_logits\n",
    "    answer_end_scores = outputs.end_logits\n",
    "    \n",
    "    answer_start = pt.argmax(answer_start_scores)  # Get the most likely beginning of answer with the argmax of the score\n",
    "    answer_end = pt.argmax(answer_end_scores) + 1  # Get the most likely end of answer with the argmax of the score\n",
    "    \n",
    "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end]))\n",
    "    start_predictions = pt.softmax(answer_start_scores, dim=1).tolist()[0]\n",
    "    end_predictions = pt.softmax(answer_end_scores, dim=1).tolist()[0]\n",
    "\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Answer: {answer}\")\n",
    "    print(f\"Start Confidence: {start_predictions[answer_start]}\")\n",
    "    print(f\"End Confidence: {end_predictions[answer_end]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://huggingface.co/transformers/task_summary.html#question-answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT\n",
    "\n",
    "    # https://huggingface.co/bert-large-uncased-whole-word-masking-finetuned-squad\n",
    "\n",
    "    #https://huggingface.co/csarron/bert-base-uncased-squad-v1\n",
    "#MODEL = 'csarron/bert-base-uncased-squad-v1'\n",
    "\n",
    "    #https://huggingface.co/phiyodr/bert-base-finetuned-squad2\n",
    "#MODEL = 'phiyodr/bert-base-finetuned-squad2'\n",
    "\n",
    "    #https://huggingface.co/phiyodr/bert-large-finetuned-squad2\n",
    "#MODEL = 'phiyodr/bert-large-finetuned-squad2'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROBERTA\n",
    "\n",
    "    #https://huggingface.co/csarron/roberta-base-squad-v1\n",
    "#MODEL = 'csarron/roberta-base-squad-v1'\n",
    "\n",
    "    #https://huggingface.co/phiyodr/roberta-large-finetuned-squad2\n",
    "#MODEL = 'phiyodr/roberta-large-finetuned-squad2'\n",
    "\n",
    "    #https://huggingface.co/deepset/roberta-base-squad2\n",
    "#MODEL = 'deepset/roberta-base-squad2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = [ 'phiyodr/roberta-large-finetuned-squad2', 'deepset/roberta-base-squad2',\n",
    "          'phiyodr/bert-large-finetuned-squad2', 'phiyodr/bert-base-finetuned-squad2', \n",
    "          'valhalla/t5-base-squad',\n",
    "          'tli8hf/unqover-bert-base-uncased-newsqa', 'tli8hf/unqover-roberta-base-newsqa',\n",
    "          'tli8hf/unqover-bert-large-uncased-newsqa', 'tli8hf/unqover-roberta-large-newsqa']\n",
    "\n",
    "#'bert-large-uncased-whole-word-masking-finetuned-squad',\n",
    "#'csarron/roberta-base-squad-v1', 'csarron/bert-base-uncased-squad-v1',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'phiyodr/bert-base-finetuned-squad2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'ConvBertForQuestionAnswering', 'LEDForQuestionAnswering', 'DistilBertForQuestionAnswering', 'AlbertForQuestionAnswering', 'CamembertForQuestionAnswering', 'BartForQuestionAnswering', 'MBartForQuestionAnswering', 'LongformerForQuestionAnswering', 'XLMRobertaForQuestionAnswering', 'SqueezeBertForQuestionAnswering', \n",
    "# 'FlaubertForQuestionAnsweringSimple', 'MobileBertForQuestionAnswering', 'XLMForQuestionAnsweringSimple', 'ElectraForQuestionAnswering', 'ReformerForQuestionAnswering', 'FunnelForQuestionAnswering', 'LxmertForQuestionAnswering', 'MPNetForQuestionAnswering', 'DebertaForQuestionAnswering'\n",
    "# 'RobertaForQuestionAnswering', 'BertForQuestionAnswering', 'XLNetForQuestionAnsweringSimple', \n",
    "qa_specific = pipeline('question-answering', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "beyonce_question = 'Jay Z and Beyonce attended which event together in August of 2011?'\n",
    "amazon_question = 'Which name is also used to describe the Amazon rainforest in English?'\n",
    "question_example = 'When was the Tower Theatre built?'\n",
    "#response_example = '1939'\n",
    "context_example = 'The popular neighborhood known as the Tower District is centered around the historic Tower Theatre, which is included on the National List of Historic Places. The theater was built in 1939 and is at Olive and Wishon Avenues in the heart of the Tower District. (The name of the theater refers to a well-known landmark water tower, which is actually in another nearby area). The Tower District neighborhood is just north of downtown Fresno proper, and one-half mile south of Fresno City College. Although the neighborhood was known as a residential area prior, the early commercial establishments of the Tower District began with small shops and services that flocked to the area shortly after World War II. The character of small local businesses largely remains today. To some extent, the businesses of the Tower District were developed due to the proximity of the original Fresno Normal School, (later renamed California State University at Fresno). In 1916 the college moved to what is now the site of Fresno City College one-half mile north of the Tower District.'\n",
    "amazon_context_example= \"The Amazon rainforest (Portuguese: Floresta AmazÃ´nica or AmazÃ´nia; Spanish: Selva AmazÃ³nica, AmazonÃ­a or usually Amazonia; French: ForÃªt amazonienne; Dutch: Amazoneregenwoud), also known in English as Amazonia or the Amazon Jungle, is a moist broadleaf forest that covers most of the Amazon basin of South America. This basin encompasses 7,000,000 square kilometres (2,700,000 sq mi), of which 5,500,000 square kilometres (2,100,000 sq mi) are covered by the rainforest. This region includes territory belonging to nine nations. The majority of the forest is contained within Brazil, with 60% of the rainforest, followed by Peru with 13%, Colombia with 10%, and with minor amounts in Venezuela, Ecuador, Bolivia, Guyana, Suriname and French Guiana. States or departments in four nations contain 'Amazonas' in their names. The Amazon represents over half of the planet's remaining rainforests, and comprises the largest and most biodiverse tract of tropical rainforest in the world, with an estimated 390 billion individual trees divided into 16,000 species.\"\n",
    "beyonce_context= 'In August, the couple attended the 2011 MTV Video Music Awards, at which BeyoncÃ© performed \"Love on Top\" and started the performance saying \"Tonight I want you to stand up on your feet, I want you to feel the love that\\'s growing inside of me\". At the end of the performance, she dropped her microphone, unbuttoned her blazer and rubbed her stomach, confirming her pregnancy she had alluded to earlier in the evening. Her appearance helped that year\\'s MTV Video Music Awards become the most-watched broadcast in MTV history, pulling in 12.4 million viewers; the announcement was listed in Guinness World Records for \"most tweets per second recorded for a single event\" on Twitter, receiving 8,868 tweets per second and \"Beyonce pregnant\" was the most Googled term the week of August 29, 2011.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.9739360213279724, 'start': 184, 'end': 188, 'answer': '1939'}\n",
      "{'score': 0.6646409034729004, 'start': 201, 'end': 230, 'answer': 'Amazonia or the Amazon Jungle'}\n",
      "{'score': 0.5714967846870422, 'start': 40, 'end': 62, 'answer': 'MTV Video Music Awards'}\n"
     ]
    }
   ],
   "source": [
    "print(qa_specific(question=question_example, context=context_example))\n",
    "print(qa_specific(question=amazon_question, context=amazon_context_example))\n",
    "print(qa_specific(question=beyonce_question, context=beyonce_context))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 'over 32+', score: 0.6992, start: 268, end: 276\n",
      "Answer: '100+', score: 0.4942, start: 298, end: 302\n",
      "Answer: 'general-purpose\n",
      "    architectures', score: 0.2448, start: 98, end: 131\n",
      "Answer: 'TensorFlow 2.0 and PyTorch.', score: 0.9836, start: 351, end: 378\n"
     ]
    }
   ],
   "source": [
    "result = qa_specific(question=questions, context=text)\n",
    "for res in result:\n",
    "    print(f\"Answer: '{res['answer']}', score: {round(res['score'], 4)}, start: {res['start']}, end: {res['end']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XLNET - No funciona\n",
    "\n",
    "#https://huggingface.co/jkgrad/xlnet-base-squadv2\n",
    "#MODEL = 'jkgrad/xlnet-base-squadv2'\n",
    "\n",
    "#MODEL = 'jkgrad/xlnet-base-cased-squad-quoref'\n",
    "\n",
    "# https://huggingface.co/saburbutt/xlnet_large_tweetqa\n",
    "#MODEL = 'saburbutt/xlnet_large_tweetqa'\n",
    "\n",
    "#from transformers import XLNetTokenizerFast, XLNetForQuestionAnsweringSimple\n",
    "\n",
    "#tokenizer = XLNetTokenizerFast.from_pretrained(MODEL)\n",
    "#model = XLNetForQuestionAnsweringSimple.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_specific = pipeline('question-answering', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 'over 32+', score: 0.6992, start: 268, end: 276\n",
      "Answer: '100+', score: 0.4942, start: 298, end: 302\n",
      "Answer: 'general-purpose\n",
      "    architectures', score: 0.2448, start: 98, end: 131\n",
      "Answer: 'TensorFlow 2.0 and PyTorch.', score: 0.9836, start: 351, end: 378\n"
     ]
    }
   ],
   "source": [
    "result = qa_specific(question=questions, context=text)\n",
    "for res in result:\n",
    "    print(f\"Answer: '{res['answer']}', score: {round(res['score'], 4)}, start: {res['start']}, end: {res['end']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T5\n",
    "# https://huggingface.co/ozcangundes/T5-base-for-BioQA\n",
    "MODEL = 'ozcangundes/T5-base-for-BioQA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(MODEL)\n",
    "model = T5ForConditionalGeneration.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(question,context):\n",
    "    source_encoding=tokenizer(\n",
    "        question,\n",
    "        context,\n",
    "        max_length=512,\n",
    "        padding=\"max_length\",\n",
    "        truncation=\"only_second\",\n",
    "        return_attention_mask=True,\n",
    "        add_special_tokens=True,\n",
    "        return_tensors=\"pt\")\n",
    "  \n",
    "    generated_ids=model.generate(\n",
    "          input_ids=source_encoding[\"input_ids\"],\n",
    "          attention_mask=source_encoding[\"attention_mask\"])\n",
    "\n",
    "    preds=[tokenizer.decode(gen_id, skip_special_tokens=True, clean_up_tokenization_spaces=True) for gen_id in generated_ids]\n",
    "\n",
    "    return {'answer': \"\".join(preds)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': '32'}\n",
      "{'answer': '100+'}\n",
      "{'answer': 'Transformers provides general-purpose architectures (BERT, GPT-2, Ro'}\n",
      "{'answer': 'TensorFlow 2.0'}\n"
     ]
    }
   ],
   "source": [
    "for query in questions:\n",
    "    result = get_answer(query, text)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/valhalla/t5-base-squad\n",
    "MODEL = \"valhalla/t5-base-squad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(question, context):\n",
    "    input_text = \"question: %s  context: %s </s>\" % (question, context)\n",
    "    features = tokenizer([input_text], return_tensors='pt')\n",
    "    \n",
    "    out = model.generate(input_ids=features['input_ids'], attention_mask=features['attention_mask'])\n",
    "    return tokenizer.decode(out[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'questions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-142-2b11ec01f785>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mquery\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mquestions\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_answer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'questions' is not defined"
     ]
    }
   ],
   "source": [
    "for query in questions:\n",
    "    result = get_answer(query, text)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = [ 'phiyodr/roberta-large-finetuned-squad2', 'deepset/roberta-base-squad2',\n",
    "          'phiyodr/bert-large-finetuned-squad2', 'phiyodr/bert-base-finetuned-squad2', \n",
    "          'valhalla/t5-base-squad',\n",
    "          'tli8hf/unqover-bert-base-uncased-newsqa', 'tli8hf/unqover-roberta-base-newsqa',\n",
    "          'tli8hf/unqover-bert-large-uncased-newsqa', 'tli8hf/unqover-roberta-large-newsqa']\n",
    "\n",
    "#'bert-large-uncased-whole-word-masking-finetuned-squad',\n",
    "#'csarron/roberta-base-squad-v1', 'csarron/bert-base-uncased-squad-v1',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SQUAD 2.0 DEV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#squad_dev = pd.read_excel('BERT-NER-POS-SQUAD-dev-queries.xlsx') #'NER-POS-SQUAD-dev-queries.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_dev = pd.read_excel('BERT-NER-POS-SQUAD-train.xlsx') #'NER-POS-SQUAD-train-queries.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#squad_dev = pd.read_excel('BERT-NER-POS-F-NEWSQA-ftunNEWSQA-ftunSQUAD.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'id', 'query', 'answer', 'impossible', 'plausible', 'dataset',\n",
       "       'context', 'query_ner', 'context_ner', 'answer_ner', 'query_pos',\n",
       "       'answer_pos', 'plausible_pos', 'context_pos',\n",
       "       'phiyodr/roberta-large-finetuned-squad2', 'deepset/roberta-base-squad2',\n",
       "       'phiyodr/bert-large-finetuned-squad2',\n",
       "       'phiyodr/bert-base-finetuned-squad2', 'valhalla/t5-base-squad'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_dev.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL = #'phiyodr/bert-base-finetuned-squad2'\n",
    "          ##'phiyodr/bert-large-finetuned-squad2' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#squad_dev[MODEL] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4353"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(squad_dev[MODEL].isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "#model = AutoModelForQuestionAnswering.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'ConvBertForQuestionAnswering', 'LEDForQuestionAnswering', 'DistilBertForQuestionAnswering', 'AlbertForQuestionAnswering', 'CamembertForQuestionAnswering', 'BartForQuestionAnswering', 'MBartForQuestionAnswering', 'LongformerForQuestionAnswering', 'XLMRobertaForQuestionAnswering', 'SqueezeBertForQuestionAnswering', \n",
    "# 'FlaubertForQuestionAnsweringSimple', 'MobileBertForQuestionAnswering', 'XLMForQuestionAnsweringSimple', 'ElectraForQuestionAnswering', 'ReformerForQuestionAnswering', 'FunnelForQuestionAnswering', 'LxmertForQuestionAnswering', 'MPNetForQuestionAnswering', 'DebertaForQuestionAnswering'\n",
    "# 'RobertaForQuestionAnswering', 'BertForQuestionAnswering', 'XLNetForQuestionAnsweringSimple', \n",
    "#qa_specific = pipeline('question-answering', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(squad_dev.loc[squad_dev[MODEL]=='{}']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# & (squad_dev['dataset'] == 'test')\n",
    "context_restantes = squad_dev.loc[(squad_dev[MODEL].isna()), 'context']\n",
    "print(len(context_restantes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#context_restantes.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for context in context_restantes.unique():\n",
    "    queries = squad_dev.loc[squad_dev['context'] == context, 'query'].values.tolist()\n",
    "    queries = [element for element in queries if len(element) > 0 and str(element) != 'nan']\n",
    "    if len(queries) > 0 and len(context) > 0:\n",
    "        answers = qa_specific(question=queries, context=context)\n",
    "        if len(answers) > 0:\n",
    "            for query in queries:\n",
    "                try:\n",
    "                    squad_dev.loc[(squad_dev['context'] == context) & (squad_dev['query'] == query), \n",
    "                        MODEL] = str(answers[queries.index(query)])\n",
    "                except:\n",
    "                    squad_dev.loc[(squad_dev['context'] == context) & (squad_dev['query'] == query), \n",
    "                        MODEL] = '{}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#squad_dev.to_excel('BERT-NER-POS-F-NEWSQA-ftunNEWSQA-ftunSQUAD-act.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_dev.to_excel('BERT-NER-POS-SQUAD-train.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT-NER-POS-F-NEWSQA-ftunNEWSQA-ftunSQUAD.xlsx\n",
    "#newsqa_fn.to_excel('BERT-NER-POS-F-NEWSQA-ftunNEWSQA-ftunSQUAD.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3435\n"
     ]
    }
   ],
   "source": [
    "print(sum(squad_dev[MODEL].isna()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "for context in context_restantes.unique():\n",
    "    queries = squad_dev.loc[squad_dev['context'] == context, 'query'].values.tolist()\n",
    "    for query in queries:\n",
    "        answers = get_answer(query, context)\n",
    "        squad_dev.loc[(squad_dev['context'] == context) & (squad_dev['query'] == query), MODEL] = str(answers)\n",
    "#    print(sum(squad_dev[MODEL].isna()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>id</th>\n",
       "      <th>query</th>\n",
       "      <th>answer</th>\n",
       "      <th>impossible</th>\n",
       "      <th>plausible</th>\n",
       "      <th>dataset</th>\n",
       "      <th>context</th>\n",
       "      <th>query_ner</th>\n",
       "      <th>context_ner</th>\n",
       "      <th>...</th>\n",
       "      <th>context_pos</th>\n",
       "      <th>bert-large-uncased-whole-word-masking-finetuned-squad</th>\n",
       "      <th>csarron/roberta-base-squad-v1</th>\n",
       "      <th>csarron/bert-base-uncased-squad-v1</th>\n",
       "      <th>phiyodr/roberta-large-finetuned-squad2</th>\n",
       "      <th>deepset/roberta-base-squad2</th>\n",
       "      <th>phiyodr/bert-base-finetuned-squad2</th>\n",
       "      <th>phiyodr/bert-large-finetuned-squad2</th>\n",
       "      <th>ozcangundes/T5-base-for-BioQA</th>\n",
       "      <th>valhalla/t5-base-squad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Normans</td>\n",
       "      <td>56ddde6b9a695914005b9628</td>\n",
       "      <td>In what country is Normandy located?</td>\n",
       "      <td>France</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dev</td>\n",
       "      <td>The Normans (Norman: Nourmands; French: Norman...</td>\n",
       "      <td>{'LOCATION': ['Normandy']}</td>\n",
       "      <td>{'MISC': ['Normans Norman Nourmands', 'Carolin...</td>\n",
       "      <td>...</td>\n",
       "      <td>[Tag(word='The', pos='DT', lemma='the'), Tag(w...</td>\n",
       "      <td>{'score': 0.9912782907485962, 'start': 159, 'e...</td>\n",
       "      <td>{'score': 0.9869462251663208, 'start': 159, 'e...</td>\n",
       "      <td>{'score': 0.9820709824562073, 'start': 159, 'e...</td>\n",
       "      <td>{'score': 0.9877960681915283, 'start': 159, 'e...</td>\n",
       "      <td>{'score': 0.9942156076431274, 'start': 159, 'e...</td>\n",
       "      <td>{'score': 0.9931656122207642, 'start': 159, 'e...</td>\n",
       "      <td>{'score': 0.991849422454834, 'start': 159, 'en...</td>\n",
       "      <td>{'answer': 'France'}</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Normans</td>\n",
       "      <td>56ddde6b9a695914005b9629</td>\n",
       "      <td>When were the Normans in Normandy?</td>\n",
       "      <td>10th and 11th centuries</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dev</td>\n",
       "      <td>The Normans (Norman: Nourmands; French: Norman...</td>\n",
       "      <td>{'LOCATION': ['Normandy']}</td>\n",
       "      <td>{'MISC': ['Normans Norman Nourmands', 'Carolin...</td>\n",
       "      <td>...</td>\n",
       "      <td>[Tag(word='The', pos='DT', lemma='the'), Tag(w...</td>\n",
       "      <td>{'score': 0.7390105724334717, 'start': 94, 'en...</td>\n",
       "      <td>{'score': 0.6863948702812195, 'start': 94, 'en...</td>\n",
       "      <td>{'score': 0.6613354086875916, 'start': 94, 'en...</td>\n",
       "      <td>{'score': 0.6423813700675964, 'start': 94, 'en...</td>\n",
       "      <td>{'score': 0.6264273524284363, 'start': 94, 'en...</td>\n",
       "      <td>{'score': 0.7914076447486877, 'start': 94, 'en...</td>\n",
       "      <td>{'score': 0.852700412273407, 'start': 94, 'end...</td>\n",
       "      <td>{'answer': '10th and 11th centuries'}</td>\n",
       "      <td>10th and 11th centuries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Normans</td>\n",
       "      <td>56ddde6b9a695914005b962a</td>\n",
       "      <td>From which countries did the Norse originate?</td>\n",
       "      <td>Denmark, Iceland and Norway</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dev</td>\n",
       "      <td>The Normans (Norman: Nourmands; French: Norman...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'MISC': ['Normans Norman Nourmands', 'Carolin...</td>\n",
       "      <td>...</td>\n",
       "      <td>[Tag(word='The', pos='DT', lemma='the'), Tag(w...</td>\n",
       "      <td>{'score': 0.993444561958313, 'start': 256, 'en...</td>\n",
       "      <td>{'score': 0.9788983464241028, 'start': 256, 'e...</td>\n",
       "      <td>{'score': 0.985059916973114, 'start': 256, 'en...</td>\n",
       "      <td>{'score': 0.9993707537651062, 'start': 256, 'e...</td>\n",
       "      <td>{'score': 0.9779964685440063, 'start': 256, 'e...</td>\n",
       "      <td>{'score': 0.47998306155204773, 'start': 256, '...</td>\n",
       "      <td>{'score': 0.9851764440536499, 'start': 256, 'e...</td>\n",
       "      <td>{'answer': 'Denmark, Iceland and Norway'}</td>\n",
       "      <td>Denmark, Iceland and Norway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Normans</td>\n",
       "      <td>56ddde6b9a695914005b962b</td>\n",
       "      <td>Who was the Norse leader?</td>\n",
       "      <td>Rollo</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dev</td>\n",
       "      <td>The Normans (Norman: Nourmands; French: Norman...</td>\n",
       "      <td>{'MISC': ['Norse'], 'TITLE': ['leader']}</td>\n",
       "      <td>{'MISC': ['Normans Norman Nourmands', 'Carolin...</td>\n",
       "      <td>...</td>\n",
       "      <td>[Tag(word='The', pos='DT', lemma='the'), Tag(w...</td>\n",
       "      <td>{'score': 0.9917401671409607, 'start': 308, 'e...</td>\n",
       "      <td>{'score': 0.9590807557106018, 'start': 308, 'e...</td>\n",
       "      <td>{'score': 0.9961839914321899, 'start': 308, 'e...</td>\n",
       "      <td>{'score': 0.9961422085762024, 'start': 308, 'e...</td>\n",
       "      <td>{'score': 0.9769473075866699, 'start': 308, 'e...</td>\n",
       "      <td>{'score': 0.9280317425727844, 'start': 308, 'e...</td>\n",
       "      <td>{'score': 0.9988728761672974, 'start': 308, 'e...</td>\n",
       "      <td>{'answer': 'Rollo'}</td>\n",
       "      <td>Rollo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Normans</td>\n",
       "      <td>56ddde6b9a695914005b962c</td>\n",
       "      <td>What century did the Normans first gain their ...</td>\n",
       "      <td>10th century</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dev</td>\n",
       "      <td>The Normans (Norman: Nourmands; French: Norman...</td>\n",
       "      <td>{'DURATION': ['century'], 'ORDINAL': ['first']}</td>\n",
       "      <td>{'MISC': ['Normans Norman Nourmands', 'Carolin...</td>\n",
       "      <td>...</td>\n",
       "      <td>[Tag(word='The', pos='DT', lemma='the'), Tag(w...</td>\n",
       "      <td>{'score': 0.44821697473526, 'start': 671, 'end...</td>\n",
       "      <td>{'score': 0.5641764998435974, 'start': 671, 'e...</td>\n",
       "      <td>{'score': 0.5815108418464661, 'start': 671, 'e...</td>\n",
       "      <td>{'score': 0.8355527520179749, 'start': 671, 'e...</td>\n",
       "      <td>{'score': 0.6819514632225037, 'start': 671, 'e...</td>\n",
       "      <td>{'score': 0.5060123205184937, 'start': 671, 'e...</td>\n",
       "      <td>{'score': 0.8878768086433411, 'start': 671, 'e...</td>\n",
       "      <td>{'answer': '10th century'}</td>\n",
       "      <td>10th</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     title                        id  \\\n",
       "0  Normans  56ddde6b9a695914005b9628   \n",
       "1  Normans  56ddde6b9a695914005b9629   \n",
       "2  Normans  56ddde6b9a695914005b962a   \n",
       "3  Normans  56ddde6b9a695914005b962b   \n",
       "4  Normans  56ddde6b9a695914005b962c   \n",
       "\n",
       "                                               query  \\\n",
       "0               In what country is Normandy located?   \n",
       "1                 When were the Normans in Normandy?   \n",
       "2      From which countries did the Norse originate?   \n",
       "3                          Who was the Norse leader?   \n",
       "4  What century did the Normans first gain their ...   \n",
       "\n",
       "                        answer  impossible plausible dataset  \\\n",
       "0                       France       False       NaN     dev   \n",
       "1      10th and 11th centuries       False       NaN     dev   \n",
       "2  Denmark, Iceland and Norway       False       NaN     dev   \n",
       "3                        Rollo       False       NaN     dev   \n",
       "4                 10th century       False       NaN     dev   \n",
       "\n",
       "                                             context  \\\n",
       "0  The Normans (Norman: Nourmands; French: Norman...   \n",
       "1  The Normans (Norman: Nourmands; French: Norman...   \n",
       "2  The Normans (Norman: Nourmands; French: Norman...   \n",
       "3  The Normans (Norman: Nourmands; French: Norman...   \n",
       "4  The Normans (Norman: Nourmands; French: Norman...   \n",
       "\n",
       "                                         query_ner  \\\n",
       "0                       {'LOCATION': ['Normandy']}   \n",
       "1                       {'LOCATION': ['Normandy']}   \n",
       "2                                               {}   \n",
       "3         {'MISC': ['Norse'], 'TITLE': ['leader']}   \n",
       "4  {'DURATION': ['century'], 'ORDINAL': ['first']}   \n",
       "\n",
       "                                         context_ner  ...  \\\n",
       "0  {'MISC': ['Normans Norman Nourmands', 'Carolin...  ...   \n",
       "1  {'MISC': ['Normans Norman Nourmands', 'Carolin...  ...   \n",
       "2  {'MISC': ['Normans Norman Nourmands', 'Carolin...  ...   \n",
       "3  {'MISC': ['Normans Norman Nourmands', 'Carolin...  ...   \n",
       "4  {'MISC': ['Normans Norman Nourmands', 'Carolin...  ...   \n",
       "\n",
       "                                         context_pos  \\\n",
       "0  [Tag(word='The', pos='DT', lemma='the'), Tag(w...   \n",
       "1  [Tag(word='The', pos='DT', lemma='the'), Tag(w...   \n",
       "2  [Tag(word='The', pos='DT', lemma='the'), Tag(w...   \n",
       "3  [Tag(word='The', pos='DT', lemma='the'), Tag(w...   \n",
       "4  [Tag(word='The', pos='DT', lemma='the'), Tag(w...   \n",
       "\n",
       "  bert-large-uncased-whole-word-masking-finetuned-squad  \\\n",
       "0  {'score': 0.9912782907485962, 'start': 159, 'e...      \n",
       "1  {'score': 0.7390105724334717, 'start': 94, 'en...      \n",
       "2  {'score': 0.993444561958313, 'start': 256, 'en...      \n",
       "3  {'score': 0.9917401671409607, 'start': 308, 'e...      \n",
       "4  {'score': 0.44821697473526, 'start': 671, 'end...      \n",
       "\n",
       "                       csarron/roberta-base-squad-v1  \\\n",
       "0  {'score': 0.9869462251663208, 'start': 159, 'e...   \n",
       "1  {'score': 0.6863948702812195, 'start': 94, 'en...   \n",
       "2  {'score': 0.9788983464241028, 'start': 256, 'e...   \n",
       "3  {'score': 0.9590807557106018, 'start': 308, 'e...   \n",
       "4  {'score': 0.5641764998435974, 'start': 671, 'e...   \n",
       "\n",
       "                  csarron/bert-base-uncased-squad-v1  \\\n",
       "0  {'score': 0.9820709824562073, 'start': 159, 'e...   \n",
       "1  {'score': 0.6613354086875916, 'start': 94, 'en...   \n",
       "2  {'score': 0.985059916973114, 'start': 256, 'en...   \n",
       "3  {'score': 0.9961839914321899, 'start': 308, 'e...   \n",
       "4  {'score': 0.5815108418464661, 'start': 671, 'e...   \n",
       "\n",
       "              phiyodr/roberta-large-finetuned-squad2  \\\n",
       "0  {'score': 0.9877960681915283, 'start': 159, 'e...   \n",
       "1  {'score': 0.6423813700675964, 'start': 94, 'en...   \n",
       "2  {'score': 0.9993707537651062, 'start': 256, 'e...   \n",
       "3  {'score': 0.9961422085762024, 'start': 308, 'e...   \n",
       "4  {'score': 0.8355527520179749, 'start': 671, 'e...   \n",
       "\n",
       "                         deepset/roberta-base-squad2  \\\n",
       "0  {'score': 0.9942156076431274, 'start': 159, 'e...   \n",
       "1  {'score': 0.6264273524284363, 'start': 94, 'en...   \n",
       "2  {'score': 0.9779964685440063, 'start': 256, 'e...   \n",
       "3  {'score': 0.9769473075866699, 'start': 308, 'e...   \n",
       "4  {'score': 0.6819514632225037, 'start': 671, 'e...   \n",
       "\n",
       "                  phiyodr/bert-base-finetuned-squad2  \\\n",
       "0  {'score': 0.9931656122207642, 'start': 159, 'e...   \n",
       "1  {'score': 0.7914076447486877, 'start': 94, 'en...   \n",
       "2  {'score': 0.47998306155204773, 'start': 256, '...   \n",
       "3  {'score': 0.9280317425727844, 'start': 308, 'e...   \n",
       "4  {'score': 0.5060123205184937, 'start': 671, 'e...   \n",
       "\n",
       "                 phiyodr/bert-large-finetuned-squad2  \\\n",
       "0  {'score': 0.991849422454834, 'start': 159, 'en...   \n",
       "1  {'score': 0.852700412273407, 'start': 94, 'end...   \n",
       "2  {'score': 0.9851764440536499, 'start': 256, 'e...   \n",
       "3  {'score': 0.9988728761672974, 'start': 308, 'e...   \n",
       "4  {'score': 0.8878768086433411, 'start': 671, 'e...   \n",
       "\n",
       "               ozcangundes/T5-base-for-BioQA       valhalla/t5-base-squad  \n",
       "0                       {'answer': 'France'}                       France  \n",
       "1      {'answer': '10th and 11th centuries'}      10th and 11th centuries  \n",
       "2  {'answer': 'Denmark, Iceland and Norway'}  Denmark, Iceland and Norway  \n",
       "3                        {'answer': 'Rollo'}                        Rollo  \n",
       "4                 {'answer': '10th century'}                         10th  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.39727702736854553, 'start': 569, 'end': 586, 'answer': '1,230 km (760 mi)'}                                                                           2\n",
       "{'score': 0.5906504988670349, 'start': 22, 'end': 56, 'answer': 'a body of treaties and legislation'}                                                             2\n",
       "{'score': 0.38328251242637634, 'start': 55, 'end': 59, 'answer': '1700'}                                                                                          2\n",
       "{'score': 0.6890050768852234, 'start': 27, 'end': 32, 'answer': 'three'}                                                                                          2\n",
       "{'score': 0.09566855430603027, 'start': 1304, 'end': 1390, 'answer': 'ensure that in the interpretation and application of the Treaties the law is observed\"'}    2\n",
       "                                                                                                                                                                 ..\n",
       "{'score': 0.39892151951789856, 'start': 450, 'end': 459, 'answer': 'six years'}                                                                                   1\n",
       "{'score': 0.9817264080047607, 'start': 392, 'end': 406, 'answer': 'photosynthesis'}                                                                               1\n",
       "{'score': 0.7548637390136719, 'start': 516, 'end': 526, 'answer': 'Zaltbommel'}                                                                                   1\n",
       "{'score': 0.8880122900009155, 'start': 251, 'end': 273, 'answer': 'cabin depressurization'}                                                                       1\n",
       "{'score': 0.25599178671836853, 'start': 482, 'end': 524, 'answer': \"L'Ã‰glise franÃ§aise Ã  la Nouvelle-Amsterdam\"}                                                  1\n",
       "Name: csarron/bert-base-uncased-squad-v1, Length: 11859, dtype: int64"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_dev[MODEL].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other pre-trained models for QA with TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModelForQuestionAnswering, TFBertForMaskedLM, TFBertForQuestionAnswering\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pretrained_squad_model(model_name):\n",
    "    model, tokenizer = None, None\n",
    "    if model_name == \"distilbertsquad1\":\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-cased-distilled-squad\",use_fast=True)\n",
    "        model = TFBertForQuestionAnswering.from_pretrained(\"distilbert-base-cased-distilled-squad\", from_pt=True)\n",
    "    elif model_name == \"distilbertsquad2\": \n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"twmkn9/distilbert-base-uncased-squad2\",use_fast=True)\n",
    "        model = TFAutoModelForQuestionAnswering.from_pretrained(\"twmkn9/distilbert-base-uncased-squad2\", from_pt=True)\n",
    "    elif model_name == \"bertsquad2\": \n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"deepset/bert-base-cased-squad2\",use_fast=True)\n",
    "        model = TFBertForQuestionAnswering.from_pretrained(\"deepset/bert-base-cased-squad2\", from_pt=True)\n",
    "    elif model_name == \"bertlargesquad2\": \n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\",use_fast=True)\n",
    "        model = TFBertForQuestionAnswering.from_pretrained(\"deepset/bert-large-uncased-whole-word-masking-squad2\", from_pt=True)\n",
    "    elif model_name == \"albertbasesquad2\": \n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"twmkn9/albert-base-v2-squad2\",use_fast=True)\n",
    "        model = TFBertForQuestionAnswering.from_pretrained(\"twmkn9/albert-base-v2-squad2\", from_pt=True)\n",
    "    elif model_name == \"distilrobertasquad2\": \n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"twmkn9/distilroberta-base-squad2\",use_fast=True)\n",
    "        model = TFBertForQuestionAnswering.from_pretrained(\"twmkn9/distilroberta-base-squad2\", from_pt=True)\n",
    "    elif model_name == \"robertasquad2\": \n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"deepset/roberta-base-squad2\",use_fast=True)\n",
    "        model = TFAutoModelForQuestionAnswering.from_pretrained(\"deepset/roberta-base-squad2\", from_pt=True)\n",
    "    elif model_name == \"bertlm\":\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\",use_fast=True)\n",
    "        model = TFBertForMaskedLM.from_pretrained(\"bert-base-uncased\", from_pt=True)\n",
    "\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2755844f39a46cc886a98c25b0dbc26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/433M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForQuestionAnswering.\n",
      "\n",
      "All the weights of TFBertForQuestionAnswering were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForQuestionAnswering for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Choose from any set of HuggingFace models to use!\n",
    "bqa_model, bqa_tokenizer = get_pretrained_squad_model(\"bertsquad2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
